{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import deepdish as dd\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from collections import namedtuple, deque\n",
    "from scipy import stats\n",
    "\n",
    "import gurobipy  as grb\n",
    "from gurobipy import *\n",
    "GRB = grb.GRB\n",
    "\n",
    "import statistics\n",
    "from cvxopt import matrix, solvers\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n",
      "The number of users: 1132\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('D:\\python\\聚类Exploration\\Baseline估计Integrate Way\\CleanData')\n",
    "#print(files)\n",
    "print(len(files))\n",
    "\n",
    "Dicblock0 = {}\n",
    "for i in range(len(files)):\n",
    "    Dicblock0[files[i]] = np.load(\"D:/python/聚类Exploration/Baseline估计Integrate Way/CleanData/\" + files[i])\n",
    "\n",
    "print('The number of users:', len(files))\n",
    "\n",
    "\n",
    "with open('D:/python/Online Forecast/Elasticity Modelling/Acorn.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    Acorn_info = dict(reader)\n",
    "    \n",
    "    \n",
    "with open('D:/python/Online Forecast/Elasticity Modelling/ToU.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    ToU_info = dict(reader)\n",
    "\n",
    "df_tarrif = pd.read_csv(\"D:/python/Online Forecast/Elasticity Modelling/Tariffs.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断 Acorn_info, ToUInfo unique类别的个数 \n",
    "def unique(Dic):\n",
    "    lis = []\n",
    "    for key,value in Dic.items():\n",
    "        lis.append(value)\n",
    "    #print(lis)\n",
    "    df = pd.DataFrame(lis)\n",
    "    return df[0].unique()\n",
    "\n",
    "def CustomerDivisonTariff(ToU_info, ToUUnique,Dicblock0):\n",
    "    \n",
    "    ## 初始化\n",
    "    TariffDic = {}\n",
    "    TariffDicStdR = {}\n",
    "    TariffDicToUR = {}\n",
    "    \n",
    "    TariffDicStdMAX = {}\n",
    "    TariffDicToUMAX= {}\n",
    "    \n",
    "        \n",
    "    for x in ToUUnique:\n",
    "        TariffDic[x] = []\n",
    "     \n",
    "        \n",
    "    ## 划分三个集合    \n",
    "    for key,value in ToU_info.items():\n",
    "        if value == 'Std':\n",
    "            TariffDic['Std'].append(Dicblock0[key+'.npy'])\n",
    "        else:\n",
    "            TariffDic['ToU'].append(Dicblock0[key+'.npy'])\n",
    "            \n",
    "    print('Number of ToU users:',len(TariffDic['ToU']))\n",
    "    print('Number of Std users:',len(TariffDic['Std']))\n",
    "    \n",
    "      \n",
    "    \n",
    "    s = 0\n",
    "    for user in range(len(TariffDic['ToU'])):\n",
    "        s += TariffDic['ToU'][user]\n",
    "    \n",
    "    sStd = 0\n",
    "    for user in range(len(TariffDic['Std'])):\n",
    "        sStd += TariffDic['Std'][user]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return s+20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normalization(load,hmin,hmax):\n",
    "    \n",
    "    load = load.reshape(-1)\n",
    "    Xmin = np.min(load)\n",
    "    Xmax = np.max(load)\n",
    "    \n",
    "    XR = (load-Xmin)/(Xmax-Xmin)\n",
    "    \n",
    "    print(np.min(XR*(hmax-hmin)+hmin),np.max(XR*(hmax-hmin)+hmin))\n",
    "    \n",
    "    return (XR*(hmax-hmin)+hmin).reshape(365,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ToU users: 251\n",
      "Number of Std users: 881\n",
      "55.0 90.0\n"
     ]
    }
   ],
   "source": [
    "ToUUnique = unique(ToU_info)\n",
    "TariffDicToUEst = CustomerDivisonTariff(ToU_info, ToUUnique,Dicblock0)\n",
    "TariffDicToUEst = load_normalization(TariffDicToUEst[:,np.arange(0,48,2)],hmin = 55,hmax = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind2012 = np.load('D:\\python\\Integrated Forecasting and Optimizing\\Imbalance Example/clean data/wind2012.npy')\n",
    "wind2012new = wind2012[:-23,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "windpower = wind2012new[:,0].reshape(365,-1)*55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing(X,Xwind,H=24):\n",
    "\n",
    "    X = X.reshape(-1,H)\n",
    "    Y = X[3:,:]\n",
    "    Xf = np.zeros((Y.shape[0]*H,4))\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(H):\n",
    "            if j < 23:\n",
    "                Xf[i*H+j,:] = np.array([X[i,j],X[i+1,j],X[i+1,j+1],X[i+2,j]])\n",
    "            else:\n",
    "                Xf[i*H+j,:] = np.array([X[i,j],X[i+1,j],X[i+2,0],X[i+2,j]])\n",
    "            \n",
    "#             if j < 23 & j>0:               \n",
    "#                 Xf[i*H+j,:] = np.array([X[i,j],X[i+1,j],X[i+1,j+1],X[i+2,j],X[i+2,j-1]])\n",
    "#             elif j == 23:\n",
    "#                 Xf[i*H+j,:] = np.array([X[i,j],X[i+1,j],X[i+2,0],X[i+2,j],X[i+2,j-1]])\n",
    "#             elif j == 0:\n",
    "#                 Xf[i*H+j,:] = np.array([X[i,j],X[i+1,j],X[i+1,j+1],X[i+2,j],X[i+1,23]])\n",
    "    \n",
    "    trainsize = int(Y.shape[0]*0.8)*24\n",
    "    \n",
    "    Xwindnew = Xwind[3*H:,:]\n",
    "    \n",
    "    print(Xf.shape,Xwindnew.shape)\n",
    "    \n",
    "    #Xf = np.hstack((Xl,Xwind[3*H:,:]))\n",
    "    \n",
    "    Xmin = np.min(np.hstack((Xf,Xwindnew))[:trainsize,:],axis = 0)\n",
    "    Xmax = np.max(np.hstack((Xf,Xwindnew))[:trainsize,:],axis = 0)\n",
    "    \n",
    "    Ymin = np.min(Y.reshape(-1)[:trainsize,])\n",
    "    Ymax = np.max(Y.reshape(-1)[:trainsize,])\n",
    "    \n",
    "    XTrR = (np.hstack((Xf,Xwindnew))[:trainsize,:]-Xmin)/(Xmax-Xmin)\n",
    "    XTeR = (np.hstack((Xf,Xwindnew))[trainsize:,:]-Xmin)/(Xmax-Xmin)\n",
    "    \n",
    "    YTrR = (Y.reshape(-1)[:trainsize,]-Ymin)/(Ymax-Ymin)\n",
    "    YTeR = (Y.reshape(-1)[trainsize:,]-Ymin)/(Ymax-Ymin)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return XTrR,XTeR,YTrR,YTeR,Y.reshape(-1)[:trainsize,],Y.reshape(-1)[trainsize:,],Ymin,Ymax\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def DeProcessing(X,Xmin,Xmax):\n",
    "    \n",
    "    return (X)*(Xmax-Xmin)+Xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8688, 4) (8688, 4)\n"
     ]
    }
   ],
   "source": [
    "XTrR,XTeR,YTrR,YTeR,YTr,YTe,Ymin,Ymax = \\\n",
    "PreProcessing((TariffDicToUEst-windpower)*1.2,wind2012new[:,1:],H=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscenarios(XTrR,K,X,YTr):\n",
    "    neigh = NearestNeighbors(n_neighbors=K)\n",
    "    neigh.fit(XTrR)\n",
    "\n",
    "    scenarios = np.zeros((X.shape[0],K))\n",
    "    for i in range(X.shape[0]):\n",
    "        index = neigh.kneighbors(X[i,:][np.newaxis,:])[1].reshape(-1)\n",
    "        for k in range(K):\n",
    "            scenarios[i,k] = YTr[index[k]]\n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenariosnet = getscenarios(XTrR,200,XTeR,YTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1752, 200)\n"
     ]
    }
   ],
   "source": [
    "print(scenariosnet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twostageLP_temporal(scenarios,true,K,\\\n",
    "                        cd1=18,cd2=16,cu1=55,cu2=60,Beta=0.3):\n",
    "    #print(scenarios.shape)\n",
    "    m=grb.Model(\"toyDA\")\n",
    "    m.Params.LogToConsole = 0\n",
    "    \n",
    "    Pg1DA = m.addVar(vtype=GRB.CONTINUOUS)\n",
    "    Pg2DA = m.addVar(vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    m.addConstr(Pg1DA <= 70)\n",
    "    m.addConstr(-Pg1DA <= 0)\n",
    "    \n",
    "    m.addConstr(Pg2DA <= 70)\n",
    "    m.addConstr(-Pg2DA <= 0)\n",
    "    \n",
    "    prediction = m.addVar(lb=0,vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    m.addConstr(Pg1DA + Pg2DA == prediction)\n",
    "    \n",
    "    Pup1_xi = m.addVars(range(K),lb = 0, ub = 60,vtype=GRB.CONTINUOUS)\n",
    "    Pup2_xi = m.addVars(range(K),lb = 0, ub = 60,vtype=GRB.CONTINUOUS)\n",
    "    Pdown1_xi = m.addVars(range(K),lb = 0, ub = 60,vtype=GRB.CONTINUOUS)\n",
    "    Pdown2_xi = m.addVars(range(K),lb = 0, ub = 60,vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    \n",
    "    eta_xi = m.addVars(range(K),lb = 0, vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    alpha = m.addVar(lb=-GRB.INFINITY,vtype=GRB.CONTINUOUS)\n",
    "    s = 0\n",
    "    \n",
    "    for i in range(K):\n",
    "        m.addConstr(-Pdown1_xi[i] - Pdown2_xi[i] + Pup1_xi[i] +\\\n",
    "                        Pup2_xi[i]  == scenarios[i] - prediction)\n",
    "        \n",
    "        m.addConstr(-cd1*Pdown1_xi[i] - cd2*Pdown2_xi[i] + cu1*Pup1_xi[i] + \\\n",
    "                    cu2*Pup2_xi[i] - alpha <= eta_xi[i])\n",
    "        s = s + eta_xi[i]\n",
    "    \n",
    "    obj = 25*Pg1DA + 30*Pg2DA + alpha + s/((1-Beta)*K)\n",
    "    \n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    \n",
    "    Pg1DA = Pg1DA.x\n",
    "    Pg2DA = Pg2DA.x\n",
    "    prediction = prediction.x\n",
    "    \n",
    "    m1=grb.Model(\"toyRT\")\n",
    "    m1.Params.LogToConsole = 0\n",
    "    \n",
    "    Pup1 = m1.addVar(lb = -GRB.INFINITY, vtype=GRB.CONTINUOUS)\n",
    "    Pup2 = m1.addVar(lb = -GRB.INFINITY, vtype=GRB.CONTINUOUS)\n",
    "    Pdown1 = m1.addVar(lb = -GRB.INFINITY, vtype=GRB.CONTINUOUS)\n",
    "    Pdown2 = m1.addVar(lb = -GRB.INFINITY, vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "  \n",
    "    \n",
    "    m1.addConstr(Pup1 <= 60)\n",
    "    m1.addConstr(-Pup1 <= 0)\n",
    "    \n",
    "    m1.addConstr(Pup2 <= 60)\n",
    "    m1.addConstr(-Pup2 <= 0)\n",
    "    \n",
    "    m1.addConstr(Pdown1 <= 60)\n",
    "    m1.addConstr(-Pdown1 <= 0)\n",
    "    \n",
    "    m1.addConstr(Pdown2 <= 60)\n",
    "    m1.addConstr(-Pdown2 <= 0)\n",
    "        \n",
    "\n",
    "    \n",
    "    m1.addConstr(-Pdown1 - Pdown2 + Pup1 + Pup2 + prediction - true == 0)\n",
    "    \n",
    "    \n",
    "    obj = -cd1*Pdown1 - cd2*Pdown2 + cu1*Pup1 + cu2*Pup2\n",
    "    \n",
    "    m1.setObjective(obj, GRB.MINIMIZE)\n",
    "    m1.update()\n",
    "    m1.optimize()\n",
    "    \n",
    "    return 25*Pg1DA + 30*Pg2DA + m1.objVal,25*Pg1DA + 30*Pg2DA,m1.objVal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_cvar(cost,BETA):\n",
    "    #cost = cost.reshape(-1)\n",
    "    cost = np.array(cost)\n",
    "    quantile = np.quantile(cost,BETA)\n",
    "    print(quantile)\n",
    "    #print(quantile)\n",
    "    largecost = []\n",
    "    for i in range(cost.shape[0]):\n",
    "        if cost[i]> quantile:\n",
    "            largecost.append(cost[i])\n",
    "            \n",
    "    print(np.mean(largecost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-07-09\n",
      "1746.1919339320095\n",
      "1909.5601583034138\n",
      "-163.36822437140444\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = []\n",
    "scoreDA = []\n",
    "scoreRT = []\n",
    "\n",
    "for i in range(YTe.shape[0]):   \n",
    "    overallcost,costda,costrt = twostageLP_temporal(scenariosnet[i],true = YTe[i],K=200,\\\n",
    "                                                    Beta=0.3)\n",
    "    score.append(overallcost)\n",
    "    scoreDA.append(costda)\n",
    "    scoreRT.append(costrt)\n",
    "print(np.mean(score))\n",
    "print(np.mean(scoreDA))\n",
    "print(np.mean(scoreRT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536.2928601885553\n",
      "1976.3572289142146\n"
     ]
    }
   ],
   "source": [
    "cal_cvar(score,BETA=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-07-09\n",
      "1754.101526839765\n",
      "1969.885808306509\n",
      "-215.78428146674423\n",
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = []\n",
    "scoreDA = []\n",
    "scoreRT = []\n",
    "\n",
    "for i in range(YTe.shape[0]):   \n",
    "    overallcost,costda,costrt = twostageLP_temporal(scenariosnet[i],true = YTe[i],K=200,\\\n",
    "                                                    Beta=0.5)\n",
    "    score.append(overallcost)\n",
    "    scoreDA.append(costda)\n",
    "    scoreRT.append(costrt)\n",
    "print(np.mean(score))\n",
    "print(np.mean(scoreDA))\n",
    "print(np.mean(scoreRT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766.6319017512335\n",
      "2101.80047334836\n"
     ]
    }
   ],
   "source": [
    "cal_cvar(score,BETA=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-07-09\n",
      "1770.4068358423485\n",
      "2054.789749783918\n",
      "-284.38291394157005\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = []\n",
    "scoreDA = []\n",
    "scoreRT = []\n",
    "\n",
    "for i in range(YTe.shape[0]):   \n",
    "    overallcost,costda,costrt = twostageLP_temporal(scenariosnet[i],true = YTe[i],K=200,\\\n",
    "                                                    Beta=0.7)\n",
    "    score.append(overallcost)\n",
    "    scoreDA.append(costda)\n",
    "    scoreRT.append(costrt)\n",
    "print(np.mean(score))\n",
    "print(np.mean(scoreDA))\n",
    "print(np.mean(scoreRT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983.6030824452869\n",
      "2239.179045476978\n"
     ]
    }
   ],
   "source": [
    "cal_cvar(score,BETA=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572.8832174407669\n",
      "1828.114301399907\n",
      "-255.23108395914005\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = []\n",
    "scoreDA = []\n",
    "scoreRT = []\n",
    "\n",
    "for i in range(YTe.shape[0]):   \n",
    "    overallcost,costda,costrt = twostageLP_temporal(scenariosnet[i],true = YTe[i],K=200,\\\n",
    "                                                    Beta=0)\n",
    "    score.append(overallcost)\n",
    "    scoreDA.append(costda)\n",
    "    scoreRT.append(costrt)\n",
    "print(np.mean(score))\n",
    "print(np.mean(scoreDA))\n",
    "print(np.mean(scoreRT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.04002757234161\n",
      "1573.6552580974596\n"
     ]
    }
   ],
   "source": [
    "cal_cvar(score,BETA=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./resultsNetVPP/Beta7/score_sto.txt',score)\n",
    "np.savetxt('./resultsNetVPP/Beta7/scoreDA_sto.txt',scoreDA)\n",
    "np.savetxt('./resultsNetVPP/Beta7/scoreRT_sto.txt',scoreRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
